# Use std::atomic for concurrency, volatile for special memory

Volatile is often thought to have something to do with multi-threading.
The C++ feature people often confuse volatile with is std::atomic, which guarantees the the operation on the object being seen as atomic by other threads.
Once a std::atomic object has been constructed, operations on it behave more or less as if they were inside a mutex-protected critical section, but the operations are generally implemented using special machine instructions that are more efficient than would be the case if a mutex were employed.

Consider this code
```cpp
std::atomic<int> ai(0);    // initialize ai to 0

ai = 10;                   // atomically set ai to 10

std::cout << ai;           // atomically read ai's value

++ai;                      // atomically increment ai to 11

--ai;                      // atomically decrement ai to 10
```

Assuming this is the only thread modifying ai, other threads reading ai can only see values of 0, 10, 11.
Aspects worth noting:
1) std::cout << ai only guarantees the read of ai is atomic.
Between the time of read and the time of std::cout (copies the read value to be printed), ai's value may have changed.
2) the ++, -- read-modify-write operations are also atomic

In contrast, this code with volatile
```cpp
volatile int vi(0);        // initialize vi to 0

vi = 10;                   // set vi to 10

std::cout << vi;           // read vi's value

++vi;                      // increment vi to 11

--vi;                      // decrement vi to 10
```
The volatile guarantees nothing.
This code has UB, because these statements modify ai, so if other threads are reading ai at the same time, there are simultaneous readers and writers of a memory block, and that's the definition of a data race. (_what about one writer and multiple readers at the some time?_)

In addition, consider this code
```cpp
std::atomic<int> ac(0);    // "atomic counter"

volatile int vc(0);        // "volatile counter"

// we then increment both values in two threads
/*-----  Thread 1  ----- */     /*-------  Thread 2  ------- */

         ++ac;                             ++ac;
         ++vc;                             ++vc;
```

When both have finished, ac is guaranteed to be 2.
vc is not: it can be 1, but its final value is in general unpredictable: because vc is involved in a data race, and the Standard’s decree that data races cause undefined behavior means that the code generated by compilers may end up doing literally anything. Compiler optimizations can often cause the result to be unpredictable.

As another example, consider this code:
```cpp
std::atomic<bool> valAvailable(false);

auto imptValue = computeImportantValue();  // compute value

valAvailable = true;                       // tell other task
                                           // it's available
```
As humans we know setting imptValue before valAvailable is crucial, however, all compiler sees is a pair of irrelevant variables, and as a general rule a compiler is allowed to reorder the such unrelated assignments.
Even if the compiler does not reorder, the underlying hardware might.

However, the use of std::atomic imposes restrictions on how code can be reordered, and one such restriction is no code preceding the write of a std::atomic object can be ordered to after the write.
As a result, only by declaring valAvailable atomic can we guarantee that the desired order of execution is guaranteed.

volatile does not make such order guarantees.
```cpp
volatile bool valAvailable(false);

auto imptValue = computeImportantValue();

valAvailable = true;  // other threads might see this assignment
                      // before the one to imptValue!
```

Volatile only means dealing with "special" blocks of memory, where an ordinary one would have its value remain until something overwrites it.
Say you have a normal int,
```cpp
int x;

auto y = x;           // read x
y = x;                // read x again
// compiler can optimize out the assignment to y because it's redundant with
// y's initialization (redundant loads)

// similarly
// with normal memory if you write and never read again before another write
// the first write can be optimized out (dead stores) 
x = 10;               // write x
x = 20;               // write x again
```
After compiler optimizations, such code does show up, and compiler carries out redundant loads and dead stores optimization only for normal memory but not volatile memory, whose one useful case being memory mapped IO: where the value of the particular memory location does not matter for your program, it may matter for other IO control programs.

volatile tells compiler to not perform any optimizations on this block of memory. So.
```cpp
volatile int x;
auto y = x;           // read x
y = x;                // read x again (can't be optimized away)

x = 10;               // write x (can't be optimized away)
x = 20;               // write x again

// and you can see std::atomic does not do the same job:
std::atomic<int> x;

auto y = x;           // conceptually read x (see below)
y = x;                // conceptually read x again (see below)

x = 10;               // write x
x = 20;               // write x again

// the atomic version can be optimized to:
auto y = x;           // conceptually read x (see below)
x = 20;               // write x

// in fact neither of the y assignment will compile because
// std::atomic is not copiable.
// why not? imagine this auto y = x, y needs to be an atomic
// as well, and thus compiler has to generate code that reads
// x and writes y in one single atomic operation, and hardware
// typically does not support such.
// std::atomic offers neither copy support nor move support.

// so what can you do if you want to copy the value of one
// atomic to another?
// try this:
std::atomic<int> y(x.load());     // read x

y.store(x.load());                // read x again
// both store and load are atomic, but them being different
// function calls suggests the two combined doesn't have to
// be atomic, neither in the ctor nor the 2nd call.

// compiler seeing the above code, could optimize it to
register = x.load();              // read x into register

std::atomic<int> y(register);     // init y with register value

y.store(register);                // store register value into y

// this kind of optimization causes x to be read only once,
// and this is the kind of optimization that must be avoided
// when dealing with special memory.
// to avoid this, you could see
volatile std::atomic<int> vai;    // operations on vai are
                                  // atomic and can't be
                                  // optimized away
// This could be useful if vai corresponded to a memory-mapped I/O
// location that was concurrently accessed by multiple threads.
```

As a side note, some folks prefer load and store calls on atomics to make it clear the vars being read / written are special or meant to be special.

**Takeaways**
* std::atomic is for data accessed from multiple threads without using mutexes. It’s a tool for writing concurrent software.
* volatile is for memory where reads and writes should not be optimized away. It’s a tool for working with special memory.

Snippet:
```cpp
// atomic_vs_volatile.m.cpp
#include <iostream>
#include <string>
#include <thread>
#include <future>

using namespace std::literals;

int main() {
  std::atomic<int> ai(0);
  volatile int vi = 0;

  std::thread t1([&ai, &vi](){
    ai++;
    vi++;
  });

  std::thread t2([&ai, &vi](){
    ai++;
    vi++;
  });

  // volatile has nothing to do with concurrency
  t1.join();
  t2.join();
  std::cout << "atomic: " << ai.load() << "\nvolatile: " << vi << "\n";

  // volatile does prevent optimization of the following states
  volatile int vi1 = vi;
  vi1 = vi;   // will not be optimized out
  vi1 = 10;   // will not be optimized out
  vi1 = 20;
  // why does this matter? Not in this process but if another process shares
  // this memory, or has memory mapped IO, then this kind of optimization
  // leads to wrong behaviors.
  return 0;
}

```
